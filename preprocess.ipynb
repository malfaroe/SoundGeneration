{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing tutorial implementation\n",
    "#Url: https://youtu.be/coEgwnMBuo0\n",
    "\n",
    "import music21 as m21\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Steps\\n1. Load data\\n2. Filter songs with no acceptable duration\\n3. Transpose songs yo cmaj/Amin\\n4. Encode songs with music time series representation\\n5. save songs to text file'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Steps\n",
    "1. Load data\n",
    "2. Filter songs with no acceptable duration\n",
    "3. Transpose songs yo cmaj/Amin\n",
    "4. Encode songs with music time series representation\n",
    "5. save songs to text file\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path: C:\\Users\\malfaro\\Desktop\\mae_code\\SoundGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 songs!\n",
      "Has acceptable duration? True\n",
      "Original key: g minor\n",
      "/Users/mauricioalfaro/Documents/mae_code/SoundGeneration\n",
      "Loading songs...\n",
      "Loaded 12 songs!\n",
      "Original key: g minor\n",
      "Original key: b minor\n",
      "Original key: e minor\n",
      "Original key: F major\n",
      "Original key: e minor\n",
      "Original key: e minor\n",
      "Original key: F major\n",
      "Original key: C major\n",
      "Original key: e minor\n",
      "Original key: C major\n",
      "Original key: F major\n",
      "Original key: C major\n"
     ]
    }
   ],
   "source": [
    "#1. Data loading\n",
    "DATASET_PATH = r\"/Users/mauricioalfaro/Documents/mae_code/SoundGeneration/data/essen/europa/deutschl/test/\"\n",
    "\n",
    "\n",
    "\n",
    "#Go through all the .kern files and load them together using m21\n",
    "def load_songs_in_kern(dataset_path):\n",
    "   songs = []\n",
    "   for path, subdirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "           if file[-3:] == \"krn\":\n",
    "               song = m21.converter.parse(os.path.join(path, file))#convertir a objeto de music21\n",
    "               songs.append(song)\n",
    "\n",
    "   return songs\n",
    "\n",
    "def preprocess(dataset_path):\n",
    "    print(\"Loading songs...\")\n",
    "    songs = load_songs_in_kern(dataset_path)\n",
    "    print(f\"Loaded {len(songs)} songs!\")\n",
    "              \n",
    "              \n",
    "#2. Filter by acceptable duration\n",
    "\n",
    "ACCEPTABLE_DURATIONS = [0.25, 0.5, 0.75, 1, 1.5, 2, 3, 4]\n",
    "\n",
    "def has_acceptable_duration(song, acceptable_durations):\n",
    "    \"\"\"Boolean method for checking if the songs complies with duration.\n",
    "    Se considera como referncia una negra (quarter length)\n",
    "    redonda = whole note = 4\n",
    "    blanca = half note = 2\n",
    "    blanca con punto = 3\n",
    "    negra = quarter note = 1\n",
    "    negra con punto = 1.5\n",
    "    corchea = eigth note = 0.5\n",
    "    corchea con punto = 0.75\n",
    "    semicorchea = sixteenth note = 0.25\n",
    "    \"\"\"\n",
    "    for note in song.flat.notesAndRests: \n",
    "        #flat toma todos los objetos de la cancion, los convierte en lista\n",
    "        #notesAndRests deja solo las notas y silencios, excluyendo claves, simolos, etc\n",
    "        if note.duration.quarterLength not in acceptable_durations:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "def transpose(song):\n",
    "    \"\"\"\n",
    "    - Detect the key or estimate it using music21\n",
    "    - get the interval or distance necessary to transpose to Cmaj/Amin\n",
    "    - transpose using m21 if necessary\"\"\"\n",
    "    #Get the song key\n",
    "    #usually the key is in the first measure of the song\n",
    "    parts = song.getElementsByClass(m21.stream.Part) # extracts the parts adnd extracts all the elements by part \n",
    "    #go to the first part and take all the measures in part 0 \n",
    "    measures_part0 = parts[0].getElementsByClass(m21.stream.Measure)\n",
    "    key = measures_part0[0][4] #tomo la primera parte de measures y extraigo de esa lista el elemento 4 que es key\n",
    "    \n",
    "    #In case the key is not in the song we use m21 to estimate it\n",
    "    \n",
    "    if not isinstance(key, m21.key.Key):#if the song doesnt have a key stored\n",
    "        key = song.analyze(\"key\") #estimate it...\n",
    "    #Now transpose to cmaj or A minor depending on the mode of the song...\n",
    "    if key.mode == \"major\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\")) #calculates the interval\n",
    "        \n",
    "    elif key.mode == \"minor\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A \")) #calculates the interval\n",
    "    \n",
    "    print(\"Original key:\", key)\n",
    "    #transpose de song\n",
    "    transposed_song = song.transpose(interval)\n",
    "    \n",
    "    return transposed_song\n",
    "\n",
    "\n",
    "#4. Encode songs with music time series representation\n",
    "\n",
    "def encode_song(song, time_step = 0.25):\n",
    "    \"\"\"takes a song as a music21 object\n",
    "    and returns a string in which the song has\n",
    "    been encoded into a time series music representation\n",
    "    Example:\n",
    "    a note of pitch 60 that lasts one bar would be encoded\n",
    "    as: [60,\"_\", \"_\", \"_\"]\n",
    "    Time_step = 0.25 significa que nos vamos moviendo en semicorcheas por\n",
    "    toda la canción\"\"\"\n",
    "    encoded_song = []\n",
    "\n",
    "\n",
    "    for event in song.flat.notesAndRests:#flat crea una lista de todos los elementos de la cancion\n",
    "        \"\"\"un event es una nota o rest. Por ejemplo: la canción empieza con \n",
    "        una nota larga de pitch 60 que dura 4 tiempos (un compás)\"\"\"\n",
    "        #pueden ser notes or rests\n",
    "        #if note ---> guardar la nota\n",
    "        if isinstance(event, m21.note.Note):#si el evento es una nota\n",
    "            symbol = event.pitch.midi #guarda la nota como midi (60 en este caso)\n",
    "        #if rest---> guardar como string \"r\"\n",
    "        if isinstance(event, m21.note.Rest):\n",
    "            symbol = \"r\"\n",
    "    #ahora convierte todo a time series music notation. El evento del ejemplo\n",
    "    #quedaria como [60,\"_\", \"_\", \"_\"] steps es en nro de timesteps que dura el evento. \n",
    "    #Para calcularlo tomo la duracion del evento en negras y la divido por time_step\"\"\"\n",
    "        steps = int(event.duration.quarterLength / time_step)\n",
    "        \n",
    "        #tomo e evento dividido en steps y si estoy al comnienzo guardo el simbolo, si no \n",
    "        #guardo \"_\", ya que siempre va a ser así\n",
    "        for step in range(steps):\n",
    "            if step == 0:\n",
    "                encoded_song.append(symbol)\n",
    "            else:\n",
    "                encoded_song.append(\"_\")\n",
    "            \n",
    "    #cast the encoded song into a string\n",
    "    #convierto con map todos los caracteres de encoded_song a str\n",
    "    #y luego los uno separados por un \" \"\n",
    "    encoded_song = \" \".join(map(str, encoded_song))\n",
    "    return encoded_song\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "SAVE_DIR = r\"/Users/mauricioalfaro/Documents/mae_code/SoundGeneration/dataset\" \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#nombre del directorio donde quedaran las canciones\n",
    "\n",
    "\n",
    "    \n",
    "def preprocess(dataset_path):\n",
    "    print(\"Loading songs...\")\n",
    "    songs = load_songs_in_kern(dataset_path)\n",
    "    print(f\"Loaded {len(songs)} songs!\")\n",
    "    #Filter by duration\n",
    "    for i, song in enumerate(songs):\n",
    "        if not has_acceptable_duration(song, ACCEPTABLE_DURATIONS):\n",
    "            continue #si la cancion no cumple la ignora\n",
    "        #Transpose song\n",
    "        song = transpose(song)\n",
    "        # Encode songs with music time series representation\n",
    "        encoded_song = encode_song(song)\n",
    "        \n",
    "        #5. save songs to text file  \n",
    "        save_path = os.path.join(SAVE_DIR, str(i)) #guarda cada cancion con un nro en el dir \"dataset\"\n",
    "        with open(save_path, \"w\") as fp:\n",
    "            fp.write(encoded_song)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    songs = load_songs_in_kern(DATASET_PATH)\n",
    "    print(f\"Loaded {len(songs)} songs!\")\n",
    "    song = songs[0]\n",
    "    print(f\"Has acceptable duration? {has_acceptable_duration(song, ACCEPTABLE_DURATIONS)}\")\n",
    "    \n",
    "    transposed_song = transpose(song)\n",
    "    #transposed_song.show()\n",
    "    print(os.getcwd())\n",
    "    preprocess(DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 songs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'62 _ 62 _ 62 _ 67 _ _ _ _ _ 70 _ 69 _ 67 _ 66 _ _ _ r _ 69 _ 70 _ 72 _ 74 _ _ _ _ _ 72 _ 70 _ 69 _ 67 _ _ _ r _ 62 _ 62 _ 62 _ 67 _ _ _ _ _ 70 _ 69 _ 67 _ 66 _ _ _ r _ 69 _ 70 _ 72 _ 74 _ _ _ _ _ 72 _ 70 _ 69 _ 67 _ _ _ r _ 74 _ 74 _ 74 _ 74 _ _ _ _ _ 69 _ 70 _ 67 _ 69 _ _ _ r _ 62 _ 67 _ 70 _ 69 _ _ _ _ _ 72 _ 70 _ 69 _ 67 _ _ _ r _ 74 _ 74 _ 74 _ 74 _ _ _ _ _ 69 _ 70 _ 67 _ 69 _ _ _ r _ 62 _ 67 _ 70 _ 69 _ _ _ _ _ 72 _ 70 _ 69 _ 67 _ _ _ r _'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = load_songs_in_kern(DATASET_PATH)\n",
    "print(f\"Loaded {len(songs)} songs!\")\n",
    "song = songs[0]\n",
    "\n",
    "encoded = encode_song(song)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deut5150.krn\n",
      "deut5151.krn\n",
      "deut5147.krn\n",
      "deut5153.krn\n",
      "deut5152.krn\n",
      "deut5146.krn\n",
      "deut5156.krn\n",
      "deut5157.krn\n",
      "deut5155.krn\n",
      "deut5154.krn\n",
      "CKSUM\n",
      "deut5148.krn\n",
      "deut5149.krn\n"
     ]
    }
   ],
   "source": [
    "#Ver los archivos de un directorio con os\n",
    "files = os.listdir(DATASET_PATH)\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mauricioalfaro/Documents/mae_code/SoundGeneration'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ver ruta actual\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = load_songs_in_kern(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = songs[0]\n",
    "parts = song.getElementsByClass(m21.stream.Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.stream.iterator.StreamIterator for Score:0x116e9e790 @:0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tomo la duracion del evento en negras y la divido por time_step'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\"ahora convierte todo a time series music notation. El evento del ejemplo\n",
    "    quedaria como [60,\"_\", \"_\", \"_\"] steps es en nro de timesteps que dura el evento\"\"\"\n",
    "    \n",
    "    \"\"\"Tomo la duracion del evento en negras y la divido por time_step\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
