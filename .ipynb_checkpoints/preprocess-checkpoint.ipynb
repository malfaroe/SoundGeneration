{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing tutorial implementation\n",
    "#Url: https://youtu.be/coEgwnMBuo0\n",
    "\n",
    "import music21 as m21\n",
    "import os\n",
    "import json\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Steps\\n1. Load data\\n2. Filter songs with no acceptable duration\\n3. Transpose songs yo cmaj/Amin\\n4. Encode songs with music time series representation\\n5. save songs to text file\\n6. Create s ingle file to store all songs\\n7. Mapping all the symbols of the songs with integers for the nn to read\\n8. Use the mapping to convert the single file of songs into integers\\n9. Create sequences,which are the way we feed the LSTM neural network engine'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Steps\n",
    "1. Load data\n",
    "2. Filter songs with no acceptable duration\n",
    "3. Transpose songs yo cmaj/Amin\n",
    "4. Encode songs with music time series representation\n",
    "5. save songs to text file\n",
    "6. Create s ingle file to store all songs\n",
    "7. Mapping all the symbols of the songs with integers for the nn to read\n",
    "8. Use the mapping to convert the single file of songs into integers\n",
    "9. Create sequences,which are the way we feed the LSTM neural network engine\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path: C:\\Users\\malfaro\\Desktop\\mae_code\\SoundGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading songs...\n",
      "Loaded 0 songs!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5cd5c4574ed6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-5cd5c4574ed6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0msongs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcreate_single_file_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSINGLE_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[0mcreate_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msongs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAPPING_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_training_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-5cd5c4574ed6>\u001b[0m in \u001b[0;36mgenerate_training_sequences\u001b[1;34m(sequence_length)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;31m#one-hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mvocabulary_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint_songs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#nro de symbolos unicos, que son las categorias a encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;31m#Convert the targets into a numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2704\u001b[0m     \"\"\"\n\u001b[0;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[1;32m-> 2706\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "#1. Data loading\n",
    "DATASET_PATH = r\"/Users/mauricioalfaro/Documents/mae_code/SoundGeneration/data/essen/europa/deutschl/test/\"\n",
    "SAVE_DIR = r\"/Users/mauricioalfaro/Documents/mae_code/SoundGeneration/dataset\" #directorio donde va a guardarse todo\n",
    "SINGLE_FILE_PATH = \"single_dataset\" #este es un archivo que se crea con ese nombre (text file)\n",
    "#r\"/Users/mauricioalfaro/Documents/mae_code/SoundGeneration/single_file_dataset\"\n",
    "#ahi arriba se guardaran finalmente todas las canciones en un solo archivo\n",
    "#MAPPING_PATH = r\"/Users/mauricioalfaro/Documents/mae_code/SoundGeneration/mapping.json\"\n",
    "MAPPING_PATH = \"mapping.json\" #archivo json que se creara con ese nombre\n",
    "\n",
    "\n",
    "#Go through all the .kern files and load them together using m21\n",
    "def load_songs_in_kern(dataset_path):\n",
    "   songs = []\n",
    "   for path, subdirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "           if file[-3:] == \"krn\":\n",
    "               song = m21.converter.parse(os.path.join(path, file))#convertir a objeto de music21\n",
    "               songs.append(song)\n",
    "\n",
    "   return songs\n",
    "\n",
    "def preprocess(dataset_path):\n",
    "    print(\"Loading songs...\")\n",
    "    songs = load_songs_in_kern(dataset_path)\n",
    "    print(f\"Loaded {len(songs)} songs!\")\n",
    "              \n",
    "              \n",
    "#2. Filter by acceptable duration\n",
    "\n",
    "ACCEPTABLE_DURATIONS = [0.25, 0.5, 0.75, 1, 1.5, 2, 3, 4]\n",
    "\n",
    "def has_acceptable_duration(song, acceptable_durations):\n",
    "    \"\"\"Boolean method for checking if the songs complies with duration.\n",
    "    Se considera como referncia una negra (quarter length)\n",
    "    redonda = whole note = 4\n",
    "    blanca = half note = 2\n",
    "    blanca con punto = 3\n",
    "    negra = quarter note = 1\n",
    "    negra con punto = 1.5\n",
    "    corchea = eigth note = 0.5\n",
    "    corchea con punto = 0.75\n",
    "    semicorchea = sixteenth note = 0.25\n",
    "    \"\"\"\n",
    "    for note in song.flat.notesAndRests: \n",
    "        #flat toma todos los objetos de la cancion, los convierte en lista\n",
    "        #notesAndRests deja solo las notas y silencios, excluyendo claves, simolos, etc\n",
    "        if note.duration.quarterLength not in acceptable_durations:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "def transpose(song):\n",
    "    \"\"\"\n",
    "    - Detect the key or estimate it using music21\n",
    "    - get the interval or distance necessary to transpose to Cmaj/Amin\n",
    "    - transpose using m21 if necessary\"\"\"\n",
    "    #Get the song key\n",
    "    #usually the key is in the first measure of the song\n",
    "    parts = song.getElementsByClass(m21.stream.Part) # extracts the parts adnd extracts all the elements by part \n",
    "    #go to the first part and take all the measures in part 0 \n",
    "    measures_part0 = parts[0].getElementsByClass(m21.stream.Measure)\n",
    "    key = measures_part0[0][4] #tomo la primera parte de measures y extraigo de esa lista el elemento 4 que es key\n",
    "    \n",
    "    #In case the key is not in the song we use m21 to estimate it\n",
    "    \n",
    "    if not isinstance(key, m21.key.Key):#if the song doesnt have a key stored\n",
    "        key = song.analyze(\"key\") #estimate it...\n",
    "    #Now transpose to cmaj or A minor depending on the mode of the song...\n",
    "    if key.mode == \"major\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\")) #calculates the interval\n",
    "        \n",
    "    elif key.mode == \"minor\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A \")) #calculates the interval\n",
    "    \n",
    "    print(\"Original key:\", key)\n",
    "    #transpose de song\n",
    "    transposed_song = song.transpose(interval)\n",
    "    \n",
    "    return transposed_song\n",
    "\n",
    "\n",
    "#4. Encode songs with music time series representation\n",
    "\n",
    "def encode_song(song, time_step = 0.25):\n",
    "    \"\"\"takes a song as a music21 object\n",
    "    and returns a string in which the song has\n",
    "    been encoded into a time series music representation\n",
    "    Example:\n",
    "    a note of pitch 60 that lasts one bar would be encoded\n",
    "    as: [60,\"_\", \"_\", \"_\"]\n",
    "    Time_step = 0.25 significa que nos vamos moviendo en semicorcheas por\n",
    "    toda la canción\"\"\"\n",
    "    encoded_song = []\n",
    "\n",
    "\n",
    "    for event in song.flat.notesAndRests:#flat crea una lista de todos los elementos de la cancion\n",
    "        \"\"\"un event es una nota o rest. Por ejemplo: la canción empieza con \n",
    "        una nota larga de pitch 60 que dura 4 tiempos (un compás)\"\"\"\n",
    "        #pueden ser notes or rests\n",
    "        #if note ---> guardar la nota\n",
    "        if isinstance(event, m21.note.Note):#si el evento es una nota\n",
    "            symbol = event.pitch.midi #guarda la nota como midi (60 en este caso)\n",
    "        #if rest---> guardar como string \"r\"\n",
    "        if isinstance(event, m21.note.Rest):\n",
    "            symbol = \"r\"\n",
    "    #ahora convierte todo a time series music notation. El evento del ejemplo\n",
    "    #quedaria como [60,\"_\", \"_\", \"_\"] steps es en nro de timesteps que dura el evento. \n",
    "    #Para calcularlo tomo la duracion del evento en negras y la divido por time_step\"\"\"\n",
    "        steps = int(event.duration.quarterLength / time_step)\n",
    "        \n",
    "        #tomo e evento dividido en steps y si estoy al comnienzo guardo el simbolo, si no \n",
    "        #guardo \"_\", ya que siempre va a ser así\n",
    "        for step in range(steps):\n",
    "            if step == 0:\n",
    "                encoded_song.append(symbol)\n",
    "            else:\n",
    "                encoded_song.append(\"_\")\n",
    "            \n",
    "    #cast the encoded song into a string\n",
    "    #convierto con map todos los caracteres de encoded_song a str\n",
    "    #y luego los uno separados por un \" \"\n",
    "    encoded_song = \" \".join(map(str, encoded_song))\n",
    "    return encoded_song\n",
    "\n",
    "    \n",
    "    \n",
    "#6. create a single for the whole dataset\n",
    "\n",
    "SEQUENCE_LENGTH = 64 #se usara para delimitar el inicio de una nueva cancion\n",
    "\n",
    "def load(dataset_path):#metodo para leer las canciones de su directorio de origen\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        song = fp.read() \n",
    "    return song\n",
    "    \n",
    "def create_single_file_dataset(dataset_path, single_file_path, sequence_length):\n",
    "    \n",
    "#se crea un gran string donde se almacenan todas las encoded songs separadas por un delimitador\n",
    "    new_song_delimiter = \"/ \" * sequence_length \n",
    "    #slash y espacio repetidos 64 veces delimitando, esto porque asi los lee las rnn/lstm\n",
    "    \n",
    "    songs = \"\" #inicializo el string\n",
    "\n",
    "    #load songs and add delimiters\n",
    "    for path, _, files in os.walk(dataset_path): #paseo por todo el directorio de canciones individuales\n",
    "        for file in files:\n",
    "            file_path = os.path.join(path, file) #averiguo la ubicacion exacta de la cancion\n",
    "            song = load(file_path) #metodo que load la cancion desde el directorio\n",
    "            songs = songs + song + \" \" + new_song_delimiter\n",
    "            \n",
    "    songs = songs[:-1] #recorto el espacio que quedaria en el delimitador de la ultima cancion\n",
    "    \n",
    "    #save string that contains all dataset en su directorio\n",
    "    #save_path = os.path.join(single_file_path, \"single_dataset\") \n",
    "\n",
    "    with open(single_file_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "    \n",
    "    return songs \n",
    "    \n",
    "\n",
    "#Create a mapping for the song symbols\n",
    "def create_mapping(songs, mapping_path):\n",
    "    mappings = {}\n",
    "    #create the mapping\n",
    "    songs = songs.split() #separa todos los elementos de songs en una lista\n",
    "    vocabulary = list(set(songs)) #set toma los elementos unicos de song y list los convert into list\n",
    "    for i, symbol in enumerate(vocabulary):\n",
    "        mappings[symbol] = i\n",
    "        \n",
    "    #Save the mapping into a json file for using it later\n",
    "    #save_path = os.path.join(mapping_path, \"mapping_json\") \n",
    "    with open(mapping_path, \"w\") as fp:\n",
    "        json.dump(mappings, fp, indent= 4)\n",
    " \n",
    "\n",
    "#Convert the single file into integers using the mapping\n",
    "\n",
    "def convert_songs_into_integers(songs):\n",
    "    int_songs = [ ] #vaciaremos el mapeo a una lista\n",
    "    \n",
    "    #load the mappings file (json) that contains the dictionary\n",
    "    with open(MAPPING_PATH, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "        \n",
    "    #cast songs string into a list (recordar que songs es un string)\n",
    "    songs = songs.split()\n",
    "    \n",
    "    #map songs into int\n",
    "    for symbol in songs:\n",
    "        int_songs.append(mappings[symbol])\n",
    "       \n",
    "    return int_songs\n",
    "\n",
    "\n",
    "#Generating training sequences...\n",
    "#las LSTM se estructuran tomando una secuencia de notas y prediciendo cual es la proxima\n",
    "#Por ser supervisado, se le da una secuencia y se le muestra un target; asi se va entrenando\n",
    "#Por ello tomaremos una secuencia de 64 time_steps (que equivalen a 4 compases de 4/4) como sample\n",
    "#y como target le mostramos la siguiente nota o figura\n",
    "#Para ello las secuencias se construyen considerando que se trata de un time series, mviendose\n",
    "#con un window hacia adelante\n",
    "#En este caso, dado que tenemos un sequence length de 64 timesteps, si hay 100 symbols en total\n",
    "#y nos movemos de a uno en la ventana, tendriamos un total de secuencias de 100 - 64\n",
    "\n",
    "def generate_training_sequences(sequence_length):\n",
    "    \n",
    "    #load the songs and map them to int\n",
    "    songs = load(SINGLE_FILE_PATH)\n",
    "    int_songs = convert_songs_into_integers(songs)\n",
    "    \n",
    "    #generate the training sequences\n",
    "    inputs = [] #guardar cada secuencia\n",
    "    targets = [] #guardar los targets asociados a cada secuencia\n",
    "    num_sequences = len(int_songs) - sequence_length  #cantidad de secuencias generables\n",
    "    \n",
    "    for i in range(num_sequences):\n",
    "        inputs.append(int_songs[i:sequence_length + i])\n",
    "        targets.append(int_songs[sequence_length + i])\n",
    "    #one-hot encoding\n",
    "    vocabulary_size = len(set(int_songs)) #nro de symbolos unicos, que son las categorias a encode\n",
    "    inputs = keras.utils.to_categorical(inputs, num_classes= vocabulary_size)\n",
    "    \n",
    "    #Convert the targets into a numpy array\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    return inputs, targets\n",
    "    \n",
    "\n",
    "    \n",
    "def preprocess(dataset_path):\n",
    "    print(\"Loading songs...\")\n",
    "    songs = load_songs_in_kern(dataset_path)\n",
    "    print(f\"Loaded {len(songs)} songs!\")\n",
    "    #Filter by duration\n",
    "    for i, song in enumerate(songs):\n",
    "        if not has_acceptable_duration(song, ACCEPTABLE_DURATIONS):\n",
    "            continue #si la cancion no cumple la ignora\n",
    "        #Transpose song\n",
    "        song = transpose(song)\n",
    "        # Encode songs with music time series representation\n",
    "        encoded_song = encode_song(song)\n",
    "        \n",
    "        #5. save songs to text file  \n",
    "        save_path = os.path.join(SAVE_DIR, str(i)) #guarda cada cancion con un nro en el dir \"dataset\"\n",
    "        with open(save_path, \"w\") as fp:\n",
    "            fp.write(encoded_song)\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "def main():\n",
    "    preprocess(DATASET_PATH)    \n",
    "    songs= create_single_file_dataset(SAVE_DIR,SINGLE_FILE_PATH, SEQUENCE_LENGTH)\n",
    "    create_mapping(songs, MAPPING_PATH)\n",
    "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sopla = \"abcg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sopla.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9, 10]\n",
    "a[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:3+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 2, 3]\n",
      "4\n",
      "1\n",
      "[2, 3, 4]\n",
      "5\n",
      "2\n",
      "[3, 4, 5]\n",
      "6\n",
      "3\n",
      "[4, 5, 6]\n",
      "7\n",
      "4\n",
      "[5, 6, 7]\n",
      "8\n",
      "5\n",
      "[6, 7, 8]\n",
      "9\n",
      "6\n",
      "[7, 8, 9]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a) - 3):\n",
    "    print(i)\n",
    "    print(a[i : 3 + i])\n",
    "    print(a[3 + i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-044f1ccc0778>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
